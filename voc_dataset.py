# --------------------------------------------------------
# Written by Yufei Ye (https://github.com/JudyYe)
# --------------------------------------------------------

from __future__ import print_function

import imageio
import numpy as np
import os
import xml.etree.ElementTree as ET

import torch
import torch.nn
from PIL import Image
from torch.utils.data import Dataset

import torchvision.transforms as transforms


class VOCDataset(Dataset):
    CLASS_NAMES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',
                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']
    INV_CLASS = {}
    for i in range(len(CLASS_NAMES)):
        INV_CLASS[CLASS_NAMES[i]] = i

    # TODO: Adjust data_dir according to where **you** stored the data
    def __init__(self, split, size, data_dir="VOCdevkit/VOC2007/"):
        super().__init__()
        self.split = split
        self.data_dir = data_dir
        self.size = size
        self.img_dir = os.path.join(data_dir, 'JPEGImages')
        self.ann_dir = os.path.join(data_dir, 'Annotations')

        split_file = os.path.join(data_dir, 'ImageSets/Main', split + '.txt')
        with open(split_file) as fp:
            self.index_list = [line.strip() for line in fp]

        self.anno_list = self.preload_anno()

    @classmethod
    def get_class_name(cls, index):
        return cls.CLASS_NAMES[index]

    @classmethod
    def get_class_index(cls, name):
        return cls.INV_CLASS[name]

    def __len__(self):
        return len(self.index_list)

    def preload_anno(self):
        """
        :return: a list of lables. each element is in the form of [class, weight],
         where both class and weight are a numpy array in shape of [20],
        """
        label_list = []
        for index in self.index_list: # 5011 train and val images
            fpath = os.path.join(self.ann_dir, index + '.xml')
            tree = ET.parse(fpath)
            # TODO: insert your code here, preload labels
            # define numpy range array from 1 to 20
            classArr = np.zeros((20))

            # define weight array as zeros
            weightArr = np.ones((20))

            # define a not difficult vector
            notDiffVect = np.zeros((20))

            # output name, truncation, and difficulty from xml
            nameList = tree.findall('object/name')
            diffList = tree.findall('object/difficult')

            # if index == '000126':
            #     print('found it!')

            # for loop through parsed data
            for i in range(len(nameList)):

                if(diffList[i].text == '1' and notDiffVect[self.get_class_index(nameList[i].text)] == 0):
                    weightArr[self.get_class_index(nameList[i].text)] = 0
                if(diffList[i].text == '0'):
                    notDiffVect[self.get_class_index(nameList[i].text)] = 1
                    weightArr[self.get_class_index(nameList[i].text)] = 1
                classArr[self.get_class_index(nameList[i].text)] = 1


            # append both classes and weights to label_list
            label_list.append(np.append(classArr[:,np.newaxis], weightArr[:,np.newaxis], axis=1))

        return label_list

    def __getitem__(self, index):
        """
        :param index: a int generated by Dataloader in range [0, __len__()]
        :return: index-th element
        image: FloatTensor in shape of (C, H, W) in scale [-1, 1].
        label: LongTensor in shape of (Nc, ) binary label
        weight: FloatTensor in shape of (Nc, ) difficult or not.
        """
        findex = self.index_list[index]
        fpath = os.path.join(self.img_dir, findex + '.jpg')
        # TODO: insert your code here. hint: read image, find the labels and weight.
        # get class and weights from self.anno_list
        fclass= self.anno_list[index][:,0]
        fweight = self.anno_list[index][:,1]
        fimg = Image.open(fpath)


        transform = transforms.Compose([
            transforms.Resize((256,256)),
            transforms.RandomCrop(224),
            transforms.RandomHorizontalFlip(1),
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])

        #process image by rescaling based on webpage mean and std
        # transform = transforms.Compose([
        #     transforms.Resize((224,224)),
        #     transforms.RandomHorizontalFlip(),
        #     transforms.ToTensor(),
        #     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        # ])


        img = transform(fimg)
        lab_vec = fclass
        wgt_vec = fweight



        #convert class index to label


        image = torch.FloatTensor(img) # .permute(2,0,1)
        label = torch.FloatTensor(lab_vec)
        wgt = torch.FloatTensor(wgt_vec)
        return image, label, wgt
