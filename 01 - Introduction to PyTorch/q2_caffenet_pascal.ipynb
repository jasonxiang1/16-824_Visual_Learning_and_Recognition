{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Lets go deeper! CaffeNet for PASCAL classification (20 pts)\n",
    "\n",
    "**Note:** You are encouraged to reuse code from the previous task. Finish Q1 if you haven't already!\n",
    "\n",
    "\n",
    "As you might have seen, the performance of the SimpleCNN model was pretty low for PASCAL. This is expected as PASCAL is much more complex than FASHION MNIST, and we need a much beefier model to handle it.\n",
    "\n",
    "In this task we will be constructing a variant of the [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) architecture, known as CaffeNet. If you are familiar with Caffe, a prototxt of the network is available [here](https://github.com/BVLC/caffe/blob/master/models/bvlc_reference_caffenet/train_val.prototxt). A visualization of the network is available [here](http://ethereon.github.io/netscope/#/preset/caffenet).\n",
    "\n",
    "\n",
    "## 2.1 Build CaffeNet (5 pts)\n",
    "Here is the exact model we want to build. In this task, `torchvision.models.xxx()` is NOT allowed. Define your own CaffeNet! We use the following operator notation for the architecture:\n",
    "1. Convolution: A convolution with kernel size $k$, stride $s$, output channels $n$, padding $p$ is represented as $conv(k, s, n, p)$.\n",
    "2. Max Pooling: A max pool operation with kernel size $k$, stride $s$ as $maxpool(k, s)$.\n",
    "3. Fully connected: For $n$ output units, $FC(n)$.\n",
    "4. ReLU: For rectified linear non-linearity $relu()$\n",
    "\n",
    "```\n",
    "ARCHITECTURE:\n",
    "-> image\n",
    "-> conv(11, 4, 96, ’VALID’)\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> conv(5, 1, 256, 'SAME')\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> conv(3, 1, 384, 'SAME')\n",
    "-> relu()\n",
    "-> conv(3, 1, 384, 'SAME')\n",
    "-> relu()\n",
    "-> conv(3, 1, 256, ’SAME’)\n",
    "-> relu()\n",
    "-> max_pool(3, 2)\n",
    "-> flatten()\n",
    "-> fully_connected(4096)\n",
    "-> relu()\n",
    "-> dropout(0.5)\n",
    "-> fully_connected(4096)\n",
    "-> relu()\n",
    "-> dropout(0.5)\n",
    "-> fully_connected(20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "\n",
    "def get_fc(inp_dim, out_dim, non_linear='relu'):\n",
    "    \"\"\"\n",
    "    Mid-level API. It is useful to customize your own for large code repo.\n",
    "    :param inp_dim: int, intput dimension\n",
    "    :param out_dim: int, output dimension\n",
    "    :param non_linear: str, 'relu', 'softmax'\n",
    "    :return: list of layers [FC(inp_dim, out_dim), (non linear layer)]\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(inp_dim, out_dim))\n",
    "    if non_linear == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif non_linear == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif non_linear == 'none':\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return layers\n",
    "\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_dim = 3\n",
    "        self.conv1 = nn.Conv2d(c_dim,96,11,4,padding=0) # valid padding\n",
    "        self.pool1 = nn.MaxPool2d(3,2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5,padding=2) # same padding\n",
    "        self.pool2 = nn.MaxPool2d(3,2)\n",
    "        self.conv3 = nn.Conv2d(256,384,3,padding=1) # same padding\n",
    "        self.conv4 = nn.Conv2d(384,384,3,padding=1) # same padding\n",
    "        self.conv5 = nn.Conv2d(384,256,3,padding=1) # same padding\n",
    "        self.pool3 = nn.MaxPool2d(3,2)\n",
    "        self.flat_dim = 5*5*256 # replace with the actual value\n",
    "        self.fc1 = nn.Sequential(*get_fc(self.flat_dim, 4096, 'relu'))\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Sequential(*get_fc(4096, 4096, 'relu'))\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Sequential(*get_fc(4096, 20, 'none'))\n",
    "\n",
    "        self.nonlinear = lambda x: torch.clamp(x,0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(N, self.flat_dim) # flatten the array\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Save the Model (5 pts)\n",
    "Finish code stubs for saving the model periodically into `trainer.py`. **You will need these models later**\n",
    "\n",
    "\n",
    "## 2.3 Train and Test (5pts)\n",
    "Show clear screenshots of testing MAP and training loss for 50 epochs. Please evaluate your model to calculate the MAP on the testing dataset every 250 iterations. Use the following hyperparamters:\n",
    "* batch_size=32\n",
    "* Adam optimizer with lr=0.0001\n",
    "\n",
    "**NOTE: SAVE AT LEAST 5 EVENLY SPACED CHECKPOINTS DURING TRAINING (1 at end)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_normal_init(m):\n",
    "    if(type(m)==nn.Conv1d or type(m)==nn.Conv2d or type(m)==nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        if(m.bias is not None):\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(batch_size = 32, epochs=50, lr = 0.0001)\n",
    "args.gamma = 0.3\n",
    "weightDecay = 5e-5\n",
    "model = CaffeNet()\n",
    "model.apply(xavier_normal_init)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr,weight_decay=weightDecay) # ,weight_decay=weightDecay\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=args.gamma)\n",
    "if __name__ == '__main__':\n",
    "    test_ap, test_map = trainer.train(args, model, optimizer, scheduler)\n",
    "    print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSERT YOUR TENSORBOARD SCREENSHOTS HERE**\n",
    "\n",
    "The figures below display the learning rate, loss, and map, respectively, during training.\n",
    "\n",
    "![title](img/q2_img01_learningrate.JPG)\n",
    "\n",
    "![title](img/q2_img02_loss.JPG)\n",
    "\n",
    "![title](img/q2_img03_map.JPG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Visualizing: Conv-1 filters (5pts)\n",
    "Extract and compare the conv1 filters, at different stages of the training (at least from 3 different iterations). Show at least 5 filters."
   ]
  },
  {
   "source": [
    "The following two image grids below show the Conv1 layer filters at epochs 15, 30, and 45, respectively:\n",
    "\n",
    "![title](img/q2_img04_conv1_15epoch.JPG)\n",
    "\n",
    "![title](img/q2_img05_conv1_30epoch.JPG)\n",
    "\n",
    "![title](img/q2_img06_conv1_45epoch.JPG)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Appendex A: Training Epoch Information\n",
    "\n",
    "The following log shown below displays the batch iteration, loss, and mAP calculation at various points during the training process:\n",
    "\n",
    "Train Epoch: 0 [0 (0%)]\tLoss: 0.694260 | mAP: 0.079919 <br/>\n",
    "Train Epoch: 0 [100 (64%)]\tLoss: 0.252534 | mAP: 0.106128 <br/>\n",
    "Train Epoch: 1 [200 (27%)]\tLoss: 0.245160 | mAP: 0.125702 <br/>\n",
    "Train Epoch: 1 [300 (91%)]\tLoss: 0.220970 | mAP: 0.154655 <br/>\n",
    "Train Epoch: 2 [400 (55%)]\tLoss: 0.182752 | mAP: 0.181409 <br/>\n",
    "Train Epoch: 3 [500 (18%)]\tLoss: 0.220406 | mAP: 0.205849 <br/>\n",
    "Train Epoch: 3 [600 (82%)]\tLoss: 0.184534 | mAP: 0.200986 <br/>\n",
    "Train Epoch: 4 [700 (46%)]\tLoss: 0.213212 | mAP: 0.240417 <br/>\n",
    "Train Epoch: 5 [800 (10%)]\tLoss: 0.203305 | mAP: 0.240243 <br/>\n",
    "Train Epoch: 5 [900 (73%)]\tLoss: 0.183403 | mAP: 0.254320 <br/>\n",
    "Train Epoch: 6 [1000 (37%)]\tLoss: 0.248874 | mAP: 0.267995 <br/>\n",
    "Train Epoch: 7 [1100 (1%)]\tLoss: 0.204796 | mAP: 0.274374 <br/>\n",
    "Train Epoch: 7 [1200 (64%)]\tLoss: 0.184777 | mAP: 0.277550 <br/>\n",
    "Train Epoch: 8 [1300 (28%)]\tLoss: 0.171141 | mAP: 0.303782 <br/>\n",
    "Train Epoch: 8 [1400 (92%)]\tLoss: 0.198896 | mAP: 0.289614 <br/>\n",
    "Train Epoch: 9 [1500 (55%)]\tLoss: 0.205384 | mAP: 0.312908 <br/>\n",
    "Train Epoch: 10 [1600 (19%)]\tLoss: 0.166079 | mAP: 0.336100 <br/>\n",
    "Train Epoch: 10 [1700 (83%)]\tLoss: 0.212687 | mAP: 0.348000 <br/>\n",
    "Train Epoch: 11 [1800 (46%)]\tLoss: 0.184672 | mAP: 0.352580 <br/>\n",
    "Train Epoch: 12 [1900 (10%)]\tLoss: 0.178017 | mAP: 0.360864 <br/>\n",
    "Train Epoch: 12 [2000 (74%)]\tLoss: 0.131287 | mAP: 0.367583 <br/>\n",
    "Train Epoch: 13 [2100 (38%)]\tLoss: 0.159262 | mAP: 0.370199 <br/>\n",
    "Train Epoch: 14 [2200 (1%)]\tLoss: 0.162815 | mAP: 0.379512 <br/>\n",
    "Train Epoch: 14 [2300 (65%)]\tLoss: 0.146647 | mAP: 0.370575 <br/>\n",
    "Train Epoch: 15 [2400 (29%)]\tLoss: 0.136011 | mAP: 0.382428 <br/>\n",
    "Train Epoch: 15 [2500 (92%)]\tLoss: 0.150734 | mAP: 0.387179 <br/>\n",
    "Train Epoch: 16 [2600 (56%)]\tLoss: 0.155456 | mAP: 0.381900 <br/>\n",
    "Train Epoch: 17 [2700 (20%)]\tLoss: 0.163627 | mAP: 0.391537 <br/>\n",
    "Train Epoch: 17 [2800 (83%)]\tLoss: 0.164096 | mAP: 0.389797 <br/>\n",
    "Train Epoch: 18 [2900 (47%)]\tLoss: 0.168196 | mAP: 0.396490 <br/>\n",
    "Train Epoch: 19 [3000 (11%)]\tLoss: 0.145444 | mAP: 0.402965 <br/>\n",
    "Train Epoch: 19 [3100 (75%)]\tLoss: 0.136387 | mAP: 0.404979 <br/>\n",
    "Train Epoch: 20 [3200 (38%)]\tLoss: 0.131393 | mAP: 0.410043 <br/>\n",
    "Train Epoch: 21 [3300 (2%)]\tLoss: 0.105851 | mAP: 0.415120 <br/>\n",
    "Train Epoch: 21 [3400 (66%)]\tLoss: 0.112801 | mAP: 0.416542 <br/>\n",
    "Train Epoch: 22 [3500 (29%)]\tLoss: 0.140922 | mAP: 0.415565 <br/>\n",
    "Train Epoch: 22 [3600 (93%)]\tLoss: 0.145867 | mAP: 0.419292 <br/>\n",
    "Train Epoch: 23 [3700 (57%)]\tLoss: 0.127371 | mAP: 0.421104 <br/>\n",
    "Train Epoch: 24 [3800 (20%)]\tLoss: 0.135417 | mAP: 0.418907 <br/>\n",
    "Train Epoch: 24 [3900 (84%)]\tLoss: 0.124882 | mAP: 0.420355 <br/>\n",
    "Train Epoch: 25 [4000 (48%)]\tLoss: 0.097941 | mAP: 0.422405 <br/>\n",
    "Train Epoch: 26 [4100 (11%)]\tLoss: 0.134959 | mAP: 0.416246 <br/>\n",
    "Train Epoch: 26 [4200 (75%)]\tLoss: 0.145727 | mAP: 0.422733 <br/>\n",
    "Train Epoch: 27 [4300 (39%)]\tLoss: 0.123460 | mAP: 0.426791 <br/>\n",
    "Train Epoch: 28 [4400 (3%)]\tLoss: 0.129733 | mAP: 0.421078 <br/>\n",
    "Train Epoch: 28 [4500 (66%)]\tLoss: 0.133712 | mAP: 0.426055 <br/>\n",
    "Train Epoch: 29 [4600 (30%)]\tLoss: 0.149955 | mAP: 0.417618 <br/>\n",
    "Train Epoch: 29 [4700 (94%)]\tLoss: 0.121479 | mAP: 0.421980 <br/>\n",
    "Train Epoch: 30 [4800 (57%)]\tLoss: 0.127036 | mAP: 0.425303 <br/>\n",
    "Train Epoch: 31 [4900 (21%)]\tLoss: 0.111305 | mAP: 0.425996 <br/>\n",
    "Train Epoch: 31 [5000 (85%)]\tLoss: 0.140682 | mAP: 0.427547 <br/>\n",
    "Train Epoch: 32 [5100 (48%)]\tLoss: 0.122193 | mAP: 0.427262 <br/>\n",
    "Train Epoch: 33 [5200 (12%)]\tLoss: 0.145076 | mAP: 0.427588 <br/>\n",
    "Train Epoch: 33 [5300 (76%)]\tLoss: 0.128083 | mAP: 0.429591 <br/>\n",
    "Train Epoch: 34 [5400 (39%)]\tLoss: 0.115151 | mAP: 0.427573 <br/>\n",
    "Train Epoch: 35 [5500 (3%)]\tLoss: 0.153220 | mAP: 0.430578 <br/>\n",
    "Train Epoch: 35 [5600 (67%)]\tLoss: 0.136315 | mAP: 0.429386 <br/>\n",
    "Train Epoch: 36 [5700 (31%)]\tLoss: 0.094817 | mAP: 0.430634 <br/>\n",
    "Train Epoch: 36 [5800 (94%)]\tLoss: 0.105419 | mAP: 0.431691 <br/>\n",
    "Train Epoch: 37 [5900 (58%)]\tLoss: 0.136911 | mAP: 0.432678 <br/>\n",
    "Train Epoch: 38 [6000 (22%)]\tLoss: 0.122926 | mAP: 0.431091 <br/>\n",
    "Train Epoch: 38 [6100 (85%)]\tLoss: 0.128397 | mAP: 0.428878 <br/>\n",
    "Train Epoch: 39 [6200 (49%)]\tLoss: 0.142264 | mAP: 0.427402 <br/>\n",
    "Train Epoch: 40 [6300 (13%)]\tLoss: 0.111605 | mAP: 0.427158 <br/>\n",
    "Train Epoch: 40 [6400 (76%)]\tLoss: 0.113659 | mAP: 0.428018 <br/>\n",
    "Train Epoch: 41 [6500 (40%)]\tLoss: 0.113470 | mAP: 0.428675 <br/>\n",
    "Train Epoch: 42 [6600 (4%)]\tLoss: 0.089273 | mAP: 0.425716 <br/>\n",
    "Train Epoch: 42 [6700 (68%)]\tLoss: 0.127156 | mAP: 0.425413 <br/>\n",
    "Train Epoch: 43 [6800 (31%)]\tLoss: 0.097778 | mAP: 0.427899 <br/>\n",
    "Train Epoch: 43 [6900 (95%)]\tLoss: 0.146353 | mAP: 0.428698 <br/>\n",
    "Train Epoch: 44 [7000 (59%)]\tLoss: 0.119124 | mAP: 0.429632 <br/>\n",
    "Train Epoch: 45 [7100 (22%)]\tLoss: 0.081511 | mAP: 0.430262 <br/>\n",
    "Train Epoch: 45 [7200 (86%)]\tLoss: 0.156132 | mAP: 0.428628 <br/>\n",
    "Train Epoch: 46 [7300 (50%)]\tLoss: 0.134881 | mAP: 0.430437 <br/>\n",
    "Train Epoch: 47 [7400 (13%)]\tLoss: 0.147624 | mAP: 0.430969 <br/>\n",
    "Train Epoch: 47 [7500 (77%)]\tLoss: 0.083810 | mAP: 0.432749 <br/>\n",
    "Train Epoch: 48 [7600 (41%)]\tLoss: 0.106350 | mAP: 0.432845 <br/>\n",
    "Train Epoch: 49 [7700 (4%)]\tLoss: 0.104012 | mAP: 0.431998 <br/>\n",
    "Train Epoch: 49 [7800 (68%)]\tLoss: 0.153784 | mAP: 0.432565 <br/>\n",
    "test map: 0.41263213323264036"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}