{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Shoulders of Giants (15 points)\n",
    "As we have already seen, deep networks can sometimes be hard to optimize. Often times they heavily overfit on small training sets. Many approaches have been proposed to counter this, eg, [Krahenbuhl et al. (ICLRâ€™16)](http://arxiv.org/pdf/1511.06856.pdf), self-supervised learning, etc. However, the most effective approach remains pre-training the network on large, well-labeled supervised datasets such as ImageNet. \n",
    "\n",
    "While training on the full ImageNet data is beyond the scope of this assignment, people have already trained many popular/standard models and released them online. In this task, we will initialize a ResNet-18 model with pre-trained ImageNet weights (from `torchvision`), and finetune the network for PASCAL classification.\n",
    "\n",
    "## 4.1 Load Pre-trained Model (7 pts)\\\n",
    "Load the pre-trained weights up to the second last layer, and initialize last weights and biases from scratch.\n",
    "\n",
    "The model loading mechanism is based on names of the weights. It is easy to load pretrained models from `torchvision.models`, even when your model uses different names for weights. Please briefly explain how to load the weights correctly if the names do not match ([hint](https://discuss.pytorch.org/t/loading-weights-from-pretrained-model-with-different-module-names/11841)).\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "If you are loading pretrained parameters into a model and the names of the parameters do not match, you can still iterate through the layers of the model and load those weights. First, when you lod your pretrained parameters, turn those parameters into a list. You will be iterating through the list later. Build a for loop to iterate through your new models parameters. At each iteration of the for loop, set the layer_name and weights of the new model to be equal to the name and parameters of the pretrained model (which was turned into a list prior to the for loop). Iterate through the layers of the new model until the end. You should have a pretrained model-imported new model now.\n",
    "\n",
    "~~~\n",
    "pre_trained_model=torch.load(\"Path to the .pth file\")\n",
    "new=list(pre_trained.items())\n",
    "\n",
    "my_model_kvpair=mymodel.state_dict()\n",
    "count=0\n",
    "for key,value in my_model_kvpair.item():\n",
    "    layer_name,weights=new[count]      \n",
    "    mymodel_kvpair[key]=weights\n",
    "    count+=1\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "\n",
    "# Pre-trained weights up to second-to-last layer\n",
    "# final layers should be initialized from scratcH!\n",
    "class PretrainedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # load resnet model\n",
    "        self.modelres = models.resnet18(pretrained = True)\n",
    "        for params in self.modelres.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        self.model= nn.Sequential(self.modelres,nn.Linear(1000,20,bias=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use similar hyperparameter setup as in the scratch case. Show the learning curves (training loss, testing MAP) for 10 epochs. Please evaluate your model to calculate the MAP on the testing dataset every 100 iterations.\n",
    "\n",
    "**REMEMBER TO SAVE MODEL AT END OF TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(batch_size = 32, epochs=10, lr = 0.0001)\n",
    "args.gamma = 0.5\n",
    "weightDecay = 5e-5\n",
    "model = PretrainedResNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr, weight_decay = weightDecay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=args.gamma)\n",
    "if __name__ == '__main__':\n",
    "    test_ap, test_map = trainer.train(args, model, optimizer, scheduler)\n",
    "    print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR TB SCREENSHOTS HERE**\n",
    "\n",
    "The following two figures shown below display the training loss and training mAP for the ResNet finetuned model.\n",
    "\n",
    "![title](img/q4_img01_loss.JPG)\n",
    "\n",
    "![title](img/q4_img02_map.JPG)\n",
    "\n",
    "The following two figures shown below compared the finetuned ResNet model with the ResNet model that was trained from scratch. The curves belonging to the transfer learning ResNet model are colored in light blue.\n",
    "\n",
    "![title](img/q4_img03_loss_comparison.JPG)\n",
    "\n",
    "![title](img/q4_img04_map_comparison.JPG)"
   ]
  },
  {
   "source": [
    "Appendex A: Training Epoch Information\n",
    "\n",
    "The following log shown below displays the batch iteration, loss, and mAP calculation at various points during the training process:\n",
    "\n",
    "Train Epoch: 0 [0 (0%)]\tLoss: 0.904385 | mAP: 0.112697 <br/>\n",
    "Train Epoch: 0 [100 (64%)]\tLoss: 0.246686 | mAP: 0.318172 <br/>\n",
    "Train Epoch: 1 [200 (27%)]\tLoss: 0.145483 | mAP: 0.512955 <br/>\n",
    "Train Epoch: 1 [300 (91%)]\tLoss: 0.148025 | mAP: 0.619263 <br/>\n",
    "Train Epoch: 2 [400 (55%)]\tLoss: 0.127986 | mAP: 0.674601 <br/>\n",
    "Train Epoch: 3 [500 (18%)]\tLoss: 0.116205 | mAP: 0.710900 <br/>\n",
    "Train Epoch: 3 [600 (82%)]\tLoss: 0.118125 | mAP: 0.730045 <br/>\n",
    "Train Epoch: 4 [700 (46%)]\tLoss: 0.111438 | mAP: 0.739866 <br/>\n",
    "Train Epoch: 5 [800 (10%)]\tLoss: 0.120211 | mAP: 0.755548 <br/>\n",
    "Train Epoch: 5 [900 (73%)]\tLoss: 0.099371 | mAP: 0.761425 <br/>\n",
    "Train Epoch: 6 [1000 (37%)]\tLoss: 0.103049 | mAP: 0.767812 <br/>\n",
    "Train Epoch: 7 [1100 (1%)]\tLoss: 0.095842 | mAP: 0.778130 <br/>\n",
    "Train Epoch: 7 [1200 (64%)]\tLoss: 0.111486 | mAP: 0.776830 <br/>\n",
    "Train Epoch: 8 [1300 (28%)]\tLoss: 0.082349 | mAP: 0.783933 <br/>\n",
    "Train Epoch: 8 [1400 (92%)]\tLoss: 0.100563 | mAP: 0.788158 <br/>\n",
    "Train Epoch: 9 [1500 (55%)]\tLoss: 0.095881 | mAP: 0.792471 <br/>\n",
    "test map: 0.7933945926532152"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}