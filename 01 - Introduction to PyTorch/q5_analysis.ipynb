{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Analysis (20 points)\n",
    "By now you should know how to train networks from scratch or using from pre-trained models. You should also understand the relative performance in either scenarios. Needless to say, the performance of these models is stronger than previous non-deep architectures used until 2012. However, final performance is not the only metric we care about. It is important to get some intuition of what these models are really learning. Lets try some standard techniques.\n",
    "\n",
    "\n",
    "**FEEL FREE TO WRITE UTIL CODE IN ANOTHER FILE AND IMPORT IN THIS NOTEBOOK FOR EASE OF READABILITY**\n",
    "\n",
    "## 5.1 Nearest Neighbors (7 pts)\n",
    "Pick 3 images from PASCAL test set from different classes, and compute 4 nearest neighbors of those images over the test set. You should use and compare the following feature representations for the nearest neighbors:\n",
    "1. fc7 features from the ResNet (finetuned from ImageNet)\n",
    "2. pool5 features from the CaffeNet (trained from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaffeNet 4 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#load CaffeNet model\n",
    "def get_fc(inp_dim, out_dim, non_linear='relu'):\n",
    "    \"\"\"\n",
    "    Mid-level API. It is useful to customize your own for large code repo.\n",
    "    :param inp_dim: int, intput dimension\n",
    "    :param out_dim: int, output dimension\n",
    "    :param non_linear: str, 'relu', 'softmax'\n",
    "    :return: list of layers [FC(inp_dim, out_dim), (non linear layer)]\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(inp_dim, out_dim))\n",
    "    if non_linear == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif non_linear == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif non_linear == 'none':\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return layers\n",
    "\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_dim = 3\n",
    "        self.conv1 = nn.Conv2d(c_dim,96,11,4,padding=0) # valid padding\n",
    "        self.pool1 = nn.MaxPool2d(3,2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5,padding=2) # same padding\n",
    "        self.pool2 = nn.MaxPool2d(3,2)\n",
    "        self.conv3 = nn.Conv2d(256,384,3,padding=1) # same padding\n",
    "        self.conv4 = nn.Conv2d(384,384,3,padding=1) # same padding\n",
    "        self.conv5 = nn.Conv2d(384,256,3,padding=1) # same padding\n",
    "        self.pool3 = nn.MaxPool2d(3,2)\n",
    "        self.flat_dim = 5*5*256 # replace with the actual value\n",
    "        self.fc1 = nn.Sequential(*get_fc(self.flat_dim, 4096, 'relu'))\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Sequential(*get_fc(4096, 4096, 'relu'))\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Sequential(*get_fc(4096, 20, 'none'))\n",
    "\n",
    "        self.nonlinear = lambda x: torch.clamp(x,0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(N, self.flat_dim) # flatten the array\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "args = ARGS(batch_size = 32, use_cuda = True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modelCaffe = CaffeNet()\n",
    "    torchLoadCaffe = torch.load('saved_models/CaffeNet-50.pth')\n",
    "    modelCaffe.load_state_dict(torchLoadCaffe['model_state_dict'])\n",
    "    modelCaffe = modelCaffe.to(args.device)\n",
    "    modelCaffe.eval()\n",
    "    testfindex, testOutput, testTarget = trainer.train_output_CaffeNet(modelCaffe, args)\n",
    "\n",
    "    # build k- nearest neighbors\n",
    "    clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "    clf.fit(testOutput, testfindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocTest = VOCDataset(split='test',size=64)\n",
    "# how big are train and test sets?\n",
    "print(\"Test Set is: \", testOutput.shape)\n",
    "\n",
    "# select three random images from the test set\n",
    "num = 3\n",
    "indexArr = []\n",
    "sampleTestOutputArr = np.ones((1,6400))\n",
    "sampleTestfindexArr = np.ones((1,1))\n",
    "\n",
    "for i in range(num):\n",
    "    randNum = int(np.random.rand()*len(testOutput))\n",
    "    if randNum not in indexArr:\n",
    "        indexArr.append(randNum)\n",
    "        sampleTestOutputArr = np.concatenate((sampleTestOutputArr,testOutput[randNum][np.newaxis,:]))\n",
    "        sampleTestfindexArr = np.concatenate((sampleTestfindexArr,testfindex[randNum][np.newaxis,:]))     \n",
    "        \n",
    "sampleTestOutputArr = sampleTestOutputArr[1:,:]\n",
    "sampleTestfindexArr = sampleTestfindexArr[1:,:]\n",
    "        \n",
    "print(\"Size of Test Sample Output is: \", sampleTestOutputArr.shape)\n",
    "print(\"Size of Test Sample Output is: \", sampleTestfindexArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose four values between 1 and 5011\n",
    "testPred = clf.kneighbors(sampleTestOutputArr, return_distance=False)\n",
    "print(\"The input is: \", np.transpose(sampleTestfindexArr))\n",
    "# print(\"The prediction is: \",testPred)\n",
    "\n",
    "numVal = 3\n",
    "\n",
    "neighborImageIndex = np.zeros((numVal,4))\n",
    "\n",
    "for i in range(numVal):\n",
    "    for j in range(4):\n",
    "        neighborImageIndex[i,j] = vocTest.index_list[testPred[i,j]]\n",
    "    \n",
    "                           \n",
    "print(\"The prediction is: \", neighborImageIndex)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample prediction output:\n",
    "\n",
    "![title](img/q5_CaffeNet_img01.png)\n",
    "\n",
    "For the input image shown below ('008515.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/008515.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/008515.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/002016.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/000562.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003659.jpg)\n",
    "\n",
    "For the input image shown below ('008131.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/008131.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/008131.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/008356.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003707.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003514.jpg)\n",
    "\n",
    "For the input image shown below ('006491.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/006491.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/006491.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/001089.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/005673.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/005048.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 4 Nearest Neighbors Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "#\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-trained weights up to second-to-last layer\n",
    "# final layers should be initialized from scratcH!\n",
    "class PretrainedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # load resnet model\n",
    "        self.modelres = models.resnet18(pretrained = True)\n",
    "        for params in self.modelres.parameters():\n",
    "            params.requires_grad = False\n",
    "            \n",
    "        self.model= nn.Sequential(self.modelres,nn.Linear(1000,20,bias=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "args = ARGS(batch_size = 16, use_cuda = True)\n",
    "\n",
    "# Create ResNet model\n",
    "if __name__ == '__main__':\n",
    "    m = PretrainedResNet()\n",
    "    model = m.model\n",
    "    model = torch.load('saved_models/PreTrainedResNet-Model.pth')\n",
    "    #model.load_state_dict(torch.load('q4_resnet_pretrained_statedict.pth'))\n",
    "    model = model.to(args.device)\n",
    "    testfindex, testOutput, testTarget = trainer.train_output_ResNet(model, args)\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "    clf.fit(testOutput, testfindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocTest = VOCDataset(split='test',size=64)\n",
    "\n",
    "# how big are train and test sets?\n",
    "print(\"Test Set is: \", testOutput.shape)\n",
    "\n",
    "# select three random images from the test set\n",
    "num = 3\n",
    "indexArr = []\n",
    "sampleTestOutputArr = np.ones((1,512))\n",
    "sampleTestfindexArr = np.ones((1,1))\n",
    "\n",
    "for i in range(num):\n",
    "    randNum = int(np.random.rand()*len(testOutput))\n",
    "    if randNum not in indexArr:\n",
    "        indexArr.append(randNum)\n",
    "        sampleTestOutputArr = np.concatenate((sampleTestOutputArr,testOutput[randNum][np.newaxis,:]))\n",
    "        sampleTestfindexArr = np.concatenate((sampleTestfindexArr,testfindex[randNum][np.newaxis,:]))     \n",
    "        \n",
    "sampleTestOutputArr = sampleTestOutputArr[1:,:]\n",
    "sampleTestfindexArr = sampleTestfindexArr[1:,:]\n",
    "        \n",
    "print(\"Size of Test Sample Output is: \", sampleTestOutputArr.shape)\n",
    "print(\"Size of Test Sample Output is: \", sampleTestfindexArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose four values between 1 and 5011\n",
    "testPred = clf.kneighbors(sampleTestOutputArr, return_distance=False)\n",
    "print(\"The input is: \", np.transpose(sampleTestfindexArr))\n",
    "# print(\"The prediction is: \",testPred)\n",
    "\n",
    "numVal = 3\n",
    "\n",
    "neighborImageIndex = np.zeros((numVal,4))\n",
    "\n",
    "for i in range(numVal):\n",
    "    for j in range(4):\n",
    "        neighborImageIndex[i,j] = vocTest.index_list[testPred[i,j]]\n",
    "    \n",
    "                           \n",
    "print(\"The prediction is: \", neighborImageIndex)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample prediction output:\n",
    "\n",
    "![title](img/q5_ResNet_img02.png)\n",
    "\n",
    "For the input image shown below ('000517.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/000517.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/000517.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/006194.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/000205.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/005196.jpg)\n",
    "\n",
    "For the input image shown below ('003326.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003326.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003326.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003246.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/003977.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/001000.jpg)\n",
    "\n",
    "For the input image shown below ('001374.jpg'):\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/001374.jpg)\n",
    "\n",
    "The follow 4 neighboring images were given:\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/001374.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/009521.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/009632.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetImagePredictions/006422.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 t-SNE visualization of intermediate features (7pts)\n",
    "We can also visualize how the feature representations specialize for different classes. Take 1000 random images from the test set of PASCAL, and extract caffenet (scratch) fc7 features from those images. Compute a 2D t-SNE projection of the features, and plot them with each feature color coded by the GT class of the corresponding image. If multiple objects are active in that image, compute the color as the ”mean” color of the different classes active in that image. Legend the graph with the colors for each object class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaffeNet t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#load CaffeNet model\n",
    "def get_fc(inp_dim, out_dim, non_linear='relu'):\n",
    "    \"\"\"\n",
    "    Mid-level API. It is useful to customize your own for large code repo.\n",
    "    :param inp_dim: int, intput dimension\n",
    "    :param out_dim: int, output dimension\n",
    "    :param non_linear: str, 'relu', 'softmax'\n",
    "    :return: list of layers [FC(inp_dim, out_dim), (non linear layer)]\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(inp_dim, out_dim))\n",
    "    if non_linear == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif non_linear == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif non_linear == 'none':\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return layers\n",
    "\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_dim = 3\n",
    "        self.conv1 = nn.Conv2d(c_dim,96,11,4,padding=0) # valid padding\n",
    "        self.pool1 = nn.MaxPool2d(3,2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5,padding=2) # same padding\n",
    "        self.pool2 = nn.MaxPool2d(3,2)\n",
    "        self.conv3 = nn.Conv2d(256,384,3,padding=1) # same padding\n",
    "        self.conv4 = nn.Conv2d(384,384,3,padding=1) # same padding\n",
    "        self.conv5 = nn.Conv2d(384,256,3,padding=1) # same padding\n",
    "        self.pool3 = nn.MaxPool2d(3,2)\n",
    "        self.flat_dim = 5*5*256 # replace with the actual value\n",
    "        self.fc1 = nn.Sequential(*get_fc(self.flat_dim, 4096, 'relu'))\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Sequential(*get_fc(4096, 4096, 'relu'))\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Sequential(*get_fc(4096, 20, 'none'))\n",
    "\n",
    "        self.nonlinear = lambda x: torch.clamp(x,0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(N, self.flat_dim) # flatten the array\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out1 = out\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    modelCaffe = CaffeNet()\n",
    "    torchLoadCaffe = torch.load('saved_models/CaffeNet-50.pth')\n",
    "    modelCaffe.load_state_dict(torchLoadCaffe['model_state_dict'])\n",
    "    modelCaffe = modelCaffe.to(args.device)\n",
    "    modelCaffe.eval()\n",
    "    testfindex, testOutput, testTarget = trainer.train_output_CaffeNet(modelCaffe, args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \"color\" averaging function\n",
    "def avg_color_label(labels):\n",
    "    oneHotSum = np.sum(labels,axis=1)\n",
    "    indexHotSum = np.sum(labels*np.arange(1,21)[np.newaxis,:],axis=1)\n",
    "    \n",
    "    returnVect = indexHotSum/oneHotSum\n",
    "    \n",
    "    \n",
    "    return returnVect[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# select 1000 random images from the test set\n",
    "num = 1000\n",
    "indexArr = []\n",
    "sneTestOutputArr = np.ones((1,6400))\n",
    "sneTestTargetArr = np.ones((1,20))\n",
    "\n",
    "while len(indexArr) < 1000:\n",
    "    randNum = int(np.random.rand()*len(testOutput))\n",
    "    if randNum not in indexArr:\n",
    "        indexArr.append(randNum)\n",
    "        sneTestOutputArr = np.concatenate((sneTestOutputArr,testOutput[randNum][np.newaxis,:]))\n",
    "        sneTestTargetArr = np.concatenate((sneTestTargetArr,testTarget[randNum][np.newaxis,:]))\n",
    "    i += 1\n",
    "\n",
    "sneTestOutputArr = sneTestOutputArr[1:,:]\n",
    "sneTestTargetArr = sneTestTargetArr[1:,:]\n",
    "\n",
    "x_inbedded = TSNE(n_components=2).fit_transform(sneTestOutputArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "meanLabels = avg_color_label(sneTestTargetArr)\n",
    "#meanLabels = meanLabels/np.amax(meanLabels)\n",
    "meanLabels = np.squeeze(meanLabels,axis=1)\n",
    "plt.figure(figsize=(20,15))\n",
    "cmap = plt.get_cmap('tab20')\n",
    "recs = []\n",
    "legend = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "plt.scatter(x_inbedded[:,0],x_inbedded[:,1],c = meanLabels, cmap = plt.get_cmap('tab20'))\n",
    "for i in range(0,len(meanLabels)):\n",
    "    recs.append(matplotlib.patches.Rectangle((0,0),1,1,fc=cmap(i)))\n",
    "plt.legend(recs,legend,loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output plot is shown as the following figure below:\n",
    "\n",
    "![title](img/q5_CaffeNet_img03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Are some classes harder? (6pts)\n",
    "Show the per-class performance of your caffenet (scratch) and ResNet (finetuned) models. Try to explain, by observing examples from the dataset, why some classes are harder or easier than the others (consider the easiest and hardest class). Do some classes see large gains due to pre-training? Can you explain why that might happen?\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "### CaffeNet and PreTrained ResNet\n",
    "\n",
    "The class that had the highest AP performance was the \"person\" while the class that had the lowest performance was the \"bottle\". \n",
    "\n",
    "There can be many reasons as to why the \"person\" performs the best. Two images of the class are shown below for reference. One reason could be that the features of a person are the most distinct from the other classes in the dataset such as \"cow\" or \"aeroplane\". In addition, a nondifficult image of a person in the dataset exposes a lot of features such as the upright position, arms, legs, facial features, colored attire, which can help to differentiate it from the other images in the dataset during training.\n",
    "\n",
    "![title](img/q5_CaffeNetClassComparison/000021.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetClassComparison/000027.jpg)\n",
    "\n",
    "Two images of the class \"bottle\" are shown below for reference. Compared to the features of a human, there a significantly less features of a bottle for the model to detect. In some cases, the background may make the profile harder to detect, as shown in the image below where a close-up picture was taken of some wine bottles in a dark room. In addition, features of bottles may be more and more difficult to detect as the object is further away from the camera. For example, the label of a bottle may be easier to extract as a feature when the camera is close-up, but when the bottle is a couple of meters away from the camera, then the label would be difficult for the model to spot.\n",
    "\n",
    "![title](img/q5_CaffeNetClassComparison/009666.jpg)\n",
    "\n",
    "![title](img/q5_CaffeNetClassComparison/009709.jpg)\n",
    "\n",
    "\n",
    "### TreTrained ResNet vs From-Scratch ResNet\n",
    "\n",
    "For reference, the per-class performance of the From-Scratch ResNet model is shown below:\n",
    "\n",
    "aeroplane: 0.695663796029232 <br/>\n",
    "bicycle: 0.5622480632184709 <br/>\n",
    "bird: 0.41245039413080287 <br/>\n",
    "boat: 0.5710383505097775 <br/>\n",
    "bottle: 0.15982507088326053 <br/>\n",
    "bus: 0.5238514422134894 <br/>\n",
    "car: 0.7453615983966118 <br/>\n",
    "cat: 0.46971015685819406 <br/>\n",
    "chair: 0.4283246799656059 <br/>\n",
    "cow: 0.28834160996828456 <br/>\n",
    "diningtable: 0.40786228993246554 <br/>\n",
    "dog: 0.3652161054748284 <br/>\n",
    "horse: 0.7533615316892681 <br/>\n",
    "motorbike: 0.6526196860641374 <br/>\n",
    "person: 0.8447806695750432 <br/>\n",
    "pottedplant: 0.2523940858888379 <br/>\n",
    "sheep: 0.38764743196135676 <br/>\n",
    "sofa: 0.3606603351942273 <br/>\n",
    "train: 0.7182136028211066 <br/>\n",
    "tvmonitor: 0.4197671608743151 <br/>\n",
    "\n",
    "Though most classes saw some level of performance gain by using the transfer learning approach, the classes that saw the most significant gain were the cow, dog, and sheep classes. The gain percentage was abou 3-5% in the pretrained model. One reason for this specific gain is attributed to that the model was getting better at differentiating between the three classes. As seen through some iteration with the 4 nearest neighbors model, cows, dogs, and sheeps were frequently predicted between each other, probably due to the similar features and shape between classes. Using a transfer learning approached allow the model to run through another set of iterations to differentiate between the classes. Freezing the previous layers also allowed the model to focus on training on layer of the model, which proved to be successful in gaining performance compared to its From-Scratch counterpart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaffeNet Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine CaffeNet without the pool5 output\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_dim = 3\n",
    "        self.conv1 = nn.Conv2d(c_dim,96,11,4,padding=0) # valid padding\n",
    "        self.pool1 = nn.MaxPool2d(3,2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5,padding=2) # same padding\n",
    "        self.pool2 = nn.MaxPool2d(3,2)\n",
    "        self.conv3 = nn.Conv2d(256,384,3,padding=1) # same padding\n",
    "        self.conv4 = nn.Conv2d(384,384,3,padding=1) # same padding\n",
    "        self.conv5 = nn.Conv2d(384,256,3,padding=1) # same padding\n",
    "        self.pool3 = nn.MaxPool2d(3,2)\n",
    "        self.flat_dim = 5*5*256 # replace with the actual value\n",
    "        self.fc1 = nn.Sequential(*get_fc(self.flat_dim, 4096, 'relu'))\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Sequential(*get_fc(4096, 4096, 'relu'))\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Sequential(*get_fc(4096, 20, 'none'))\n",
    "\n",
    "        self.nonlinear = lambda x: torch.clamp(x,0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(N, self.flat_dim) # flatten the array\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output performance for each class\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    modelCaffe = CaffeNet()\n",
    "    torchLoadCaffe = torch.load('saved_models/CaffeNet-50.pth')\n",
    "    modelCaffe.load_state_dict(torchLoadCaffe['model_state_dict'])\n",
    "    modelCaffe = modelCaffe.to(args.device)\n",
    "    modelCaffe.eval()\n",
    "    \n",
    "    test_loader = utils.get_data_loader('voc', train=False, batch_size=args.test_batch_size, split='test')\n",
    "    ap, map = utils.eval_dataset_map(modelCaffe, args.device, test_loader)\n",
    "\n",
    "\n",
    "    # output values from CaffeNet, compare with the target values\n",
    "    classNames = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "                       'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "                       'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "    print(\"Accuracy Precision of CaffeNet Among Individual Classes: \")\n",
    "    for i in range(len(classNames)):\n",
    "        print(\"{}: {}\".format(classNames[i],ap[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Precision of CaffeNet Among Individual Classes: <br/>\n",
    "aeroplane: 0.6581140150639725 <br/>\n",
    "bicycle: 0.4561887044476487 <br/>\n",
    "bird: 0.35825532448861536 <br/>\n",
    "boat: 0.5089389243663608 <br/>\n",
    "bottle: 0.16395719924468152 <br/>\n",
    "bus: 0.3739061674684568 <br/>\n",
    "car: 0.6706960925944321 <br/>\n",
    "cat: 0.38321888683805233 <br/>\n",
    "chair: 0.39942472719290306 <br/>\n",
    "cow: 0.2317710070030363 <br/>\n",
    "diningtable: 0.29885085506558173 <br/>\n",
    "dog: 0.3274386268412313 <br/>\n",
    "horse: 0.6648294880873716 <br/>\n",
    "motorbike: 0.5684288971068936 <br/>\n",
    "person: 0.8086725636680325 <br/>\n",
    "pottedplant: 0.23318258506171002 <br/>\n",
    "sheep: 0.25812258618853845 <br/>\n",
    "sofa: 0.3496855596933779 <br/>\n",
    "train: 0.5634974187463156 <br/>\n",
    "tvmonitor: 0.36742932492025593 <br/>\n",
    "\n",
    "mAP:\n",
    "\n",
    "0.4322304477043734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    modelRes.eval()\n",
    "    test_loader = utils.get_data_loader('voc', train=False, batch_size=args.test_batch_size, split='test')\n",
    "    ap, map = utils.eval_dataset_map(modelRes, args.device, test_loader)\n",
    "\n",
    "\n",
    "    # output values from CaffeNet, compare with the target values\n",
    "    classNames = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "                       'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "                       'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "    print(\"Accuracy Precision of PreTrained ResNet Among Individual Classes: \")\n",
    "    for i in range(len(classNames)):\n",
    "        print(\"{}: {}\".format(classNames[i],ap[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Precision of PreTrained ResNet Among Individual Classes: <br/>\n",
    "aeroplane: 0.7213222117720576 <br/>\n",
    "bicycle: 0.5694538600068458 <br/>\n",
    "bird: 0.4367706344884813 <br/>\n",
    "boat: 0.5773203950369964 <br/>\n",
    "bottle: 0.1818182675529317 <br/>\n",
    "bus: 0.5025989148818082 <br/>\n",
    "car: 0.7382160645945922 <br/>\n",
    "cat: 0.4581863265778226 <br/>\n",
    "chair: 0.43791839747272837 <br/>\n",
    "cow: 0.32130702694874635 <br/>\n",
    "diningtable: 0.4435263229389825 <br/>\n",
    "dog: 0.4043789661300173 <br/>\n",
    "horse: 0.7495443845590672 <br/>\n",
    "motorbike: 0.6876729041809619 <br/>\n",
    "person: 0.854338868879449 <br/>\n",
    "pottedplant: 0.2733504707389632 <br/>\n",
    "sheep: 0.4169879431619927 <br/>\n",
    "sofa: 0.3385033253895445 <br/>\n",
    "train: 0.6906721981250176 <br/>\n",
    "tvmonitor: 0.46132828158342576 <br/>\n",
    "\n",
    "mAP:\n",
    "\n",
    "0.5132607882510216"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}